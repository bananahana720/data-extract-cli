================================================================================
                    STORY 5-7 ATDD TEST SKELETON COMPLETE
                           Batch Processing Optimization
================================================================================

PROJECT: Data Extraction Tool - Enterprise document processing pipeline
STORY: 5-7 Batch Processing Optimization and Incremental Updates
DATE COMPLETED: 2025-11-26
TOTAL LINES OF CODE: 3,012 lines across 9 files

================================================================================
                              DELIVERABLES
================================================================================

TEST FILES CREATED: 6 files (52 tests total)
FIXTURE FILES: 1 conftest with 4 corpus fixtures
DOCUMENTATION: 3 comprehensive guides

================================================================================
                           TEST FILES BREAKDOWN
================================================================================

1. BEHAVIORAL TESTS
   File: tests/behavioral/epic_5/test_incremental_behavior.py
   Tests: 10
   Size: ~360 lines

   Validates:
   - Change detection (new/modified/unchanged/orphan)
   - State file persistence and recovery
   - Configuration change invalidation
   - Incremental mode integration

2. UNIT TESTS
   File: tests/unit/test_cli/test_incremental_processor.py
   Tests: 17
   Size: ~550 lines

   Tests individual components:
   - FileHasher (4 tests) - SHA256 hashing
   - StateFile (4 tests) - JSON persistence
   - ChangeDetector (5 tests) - Change logic
   - GlobPatternExpander (4 tests) - Pattern matching

3. INTEGRATION TESTS
   File: tests/integration/test_cli/test_batch_incremental.py
   Tests: 12
   Size: ~500 lines

   Tests CLI integration:
   - Process command with --incremental flag (4 tests)
   - Force flag overrides (2 tests)
   - Status command output (4 tests)
   - Glob pattern CLI support (2 tests)

4. UAT JOURNEY TESTS
   File: tests/uat/journeys/test_journey_7_incremental_batch.py
   Tests: 10
   Size: ~340 lines

   User workflows:
   - Change detection panel display
   - Processing only changes
   - Time savings display
   - Force flag behavior
   - Status command
   - Orphan detection
   - Glob pattern support

5. PERFORMANCE TESTS
   File: tests/performance/test_incremental_performance.py
   Tests: 3
   Size: ~200 lines

   Performance requirements:
   - State check startup <2 seconds (1000+ files)
   - SHA256 hashing <5 seconds (100MB)
   - State load <100ms (1000+ entries)

6. FIXTURE CONFIGURATION
   File: tests/behavioral/epic_5/conftest.py
   Size: ~280 lines

   Provides:
   - incremental_state_file fixture
   - processed_corpus_with_state fixture
   - orphan_corpus fixture
   - mixed_corpus fixture

   Plus pytest marker configuration for Epic 5

DOCUMENTATION: 3 files (~1,200 lines)
   - story_5_7_test_skeleton_summary.md (comprehensive overview)
   - story_5_7_test_file_structure.txt (visual structure)
   - story_5_7_test_quick_reference.md (developer guide)

================================================================================
                            TEST STATISTICS
================================================================================

TOTAL TESTS:       52 tests
TOTAL CLASSES:     15 test classes
TOTAL FIXTURES:    4 corpus fixtures + pytest markers

BY LAYER:
  Behavioral:    10 tests (change detection, state persistence)
  Unit:          17 tests (components: hasher, state, detector, expander)
  Integration:   12 tests (CLI flags and commands)
  UAT:           10 tests (user journeys and workflows)
  Performance:    3 tests (performance baselines)

BY FEATURE:
  Change Detection:      15 tests
  State Management:       8 tests
  CLI Integration:       14 tests
  User Workflows:        10 tests
  Performance:            3 tests
  Fixtures/Setup:         2 tests

================================================================================
                          COVERAGE BY STORY AC
================================================================================

Story 5-7 Acceptance Criteria Coverage:

AC-5.7-1: Incremental Mode (--incremental flag)
  ✓ Flag accepted by process command (integration)
  ✓ State file created on first run (integration)
  ✓ Unchanged files skipped (integration)
  ✓ Only new files processed (integration)
  ✓ Startup <2 seconds (performance)

AC-5.7-2: File Change Detection
  ✓ New files detected (unit, behavioral)
  ✓ Modified files detected by hash (unit, behavioral)
  ✓ Unchanged files identified (unit, behavioral)
  ✓ Deleted files detected as orphans (unit, behavioral)
  ✓ Config changes invalidate cache (behavioral)

AC-5.7-3: State File Management
  ✓ State persists across sessions (behavioral)
  ✓ Atomic writes (no partial writes) (behavioral)
  ✓ Schema validation on load (behavioral)
  ✓ Corruption detection (unit)
  ✓ <100ms load time (performance)

AC-5.7-4: Force Flag (--force)
  ✓ Overrides incremental skip (integration)
  ✓ Reprocesses all files (integration)
  ✓ Updates state with new timestamps (integration)

AC-5.7-5: Status Command
  ✓ Displays panel with counts (integration)
  ✓ Shows processed file count (integration)
  ✓ Displays sync state (New/Modified/Unchanged) (integration)
  ✓ Offers orphan cleanup option (integration)

AC-5.7-6: Glob Pattern Support
  ✓ Pattern argument accepted (integration)
  ✓ Match count displayed (integration)
  ✓ Simple patterns work (*.pdf) (unit)
  ✓ Recursive patterns work (**/*.pdf) (unit)
  ✓ Pattern errors handled (unit)

================================================================================
                          FIXTURE ARCHITECTURE
================================================================================

All fixtures create realistic test corpora using tmp_path isolation:

incremental_state_file
  - Empty state template
  - Path: .data-extract-session/incremental-state.json
  - Schema: v1.0 with required fields

processed_corpus_with_state
  - 3 PDFs previously processed
  - State entries with hashes and timestamps
  - Output files already generated
  - Use case: Baseline incremental validation

orphan_corpus
  - 2 existing files in source
  - 3 deleted files in state only
  - Output files for all entries
  - Use case: Orphan/cleanup detection

mixed_corpus
  - 2 unchanged files (matching hashes)
  - 2 modified files (different hashes)
  - 2 new files (not in state)
  - Use case: Complete change detection testing

State File Schema (reference):
  {
    "version": "1.0",
    "source_dir": "/path",
    "output_dir": "/path",
    "config_hash": "sha256...",
    "processed_at": "ISO datetime",
    "files": {
      "/path/file.pdf": {
        "hash": "sha256...",
        "processed_at": "ISO datetime",
        "output_path": "/path/output.json",
        "size_bytes": 1024
      }
    }
  }

================================================================================
                        EXPECTED IMPLEMENTATION
================================================================================

Module: src/data_extract/cli/batch.py

Components to implement:

1. FileHasher
   - calculate_hash(file_path: str) -> str
   - Streaming SHA256 for large files
   - Return 64-char hex string

2. StateFile
   - load(path: str) -> StateFile
   - save() -> None
   - add_file(path, hash, output, size)
   - Atomic writes using temp file + rename
   - Raise SessionCorruptedError on invalid JSON

3. ChangeDetector
   - detect(source_dir: Path) -> dict
   - Returns: {
       'new': int, 'new_files': list,
       'modified': int, 'modified_files': list,
       'unchanged': int,
       'orphans': int, 'orphan_files': list,
       'reprocess_all': bool, 'reason': str
     }

4. GlobPatternExpander
   - expand(pattern: str, base_dir: str) -> list[Path]
   - Raise GlobPatternError if no matches

5. IncrementalProcessor
   - __init__(source_dir: str, state_file_path: str, config: dict = None)
   - detect_changes() -> dict
   - load_state() -> dict
   - mark_file_processed(path, hash, output)

CLI Integration:
   - Add --incremental flag to process command
   - Add --force flag (works with --incremental)
   - Add status command showing sync state
   - Add --cleanup flag to status command

================================================================================
                      RUNNING THE TESTS
================================================================================

All tests are designed to SKIP initially (RED phase - pending implementation):

# All Story 5-7 tests
pytest -m story_5_7

# By layer
pytest tests/behavioral/epic_5/
pytest tests/unit/test_cli/test_incremental_processor.py
pytest tests/integration/test_cli/test_batch_incremental.py
pytest tests/uat/journeys/test_journey_7_incremental_batch.py
pytest tests/performance/test_incremental_performance.py

# Specific test class
pytest tests/unit/test_cli/test_incremental_processor.py::TestFileHasher -v

# With coverage
pytest -m story_5_7 --cov=src/data_extract/cli/batch

Currently expected output (before implementation):
  52 skipped (implementation pending)

After implementation (target):
  52 passed (100%)

================================================================================
                        TEST DESIGN PATTERNS
================================================================================

All tests follow ATDD (Acceptance Test Driven Development) patterns:

1. GIVEN-WHEN-THEN Comments
   - Clear setup, action, and assertion phases
   - Behavioral intent documented

2. TDD RED Phase Design
   - pytest.skip("Implementation pending") blocks assertions
   - ImportError handling ensures graceful skips
   - Try/except for missing components

3. Isolation via Fixtures
   - tmp_path for file system isolation
   - No mocking of file I/O (tests use real files)
   - Clean state after each test

4. Pytest Markers
   - @pytest.mark.story_5_7 - All S5-7 tests
   - @pytest.mark.behavioral, @pytest.mark.unit, etc.
   - Enable selective execution

5. Comprehensive Docstrings
   - What is being tested (summary)
   - Acceptance criteria (Given-When-Then)
   - Expected RED failure reason

================================================================================
                      QUALITY ASSURANCE
================================================================================

✓ Python syntax validated (py_compile)
✓ All imports use standard paths (from data_extract.cli.batch)
✓ Consistent with project patterns (Story 5-1, Epic 4)
✓ Follow CLAUDE.md conventions
✓ Proper pytest markers
✓ Well-documented fixtures
✓ TDD RED phase ready

Code Quality:
✓ 100% compliant with black formatting (100 chars)
✓ Ready for ruff linting
✓ Type hints included
✓ Docstrings follow Google style

Test Quality:
✓ Clear GIVEN-WHEN-THEN structure
✓ Isolated test data (tmp_path, fixtures)
✓ No test interdependencies
✓ Assertive error messages
✓ Performance baselines included

================================================================================
                        QUICK START GUIDE
================================================================================

For developers implementing Story 5-7:

1. Read the summary: docs/artifacts/story_5_7_test_skeleton_summary.md
2. Check test structure: docs/artifacts/story_5_7_test_file_structure.txt
3. Use quick reference: docs/artifacts/story_5_7_test_quick_reference.md

4. Create module: src/data_extract/cli/batch.py

5. Implement components in order (run tests after each):
   a. FileHasher (pytest tests/unit/test_cli/test_incremental_processor.py::TestFileHasher)
   b. StateFile (pytest tests/unit/test_cli/test_incremental_processor.py::TestStateFile)
   c. ChangeDetector (pytest tests/unit/test_cli/test_incremental_processor.py::TestChangeDetector)
   d. GlobPatternExpander (pytest tests/unit/test_cli/test_incremental_processor.py::TestGlobPatternExpansion)
   e. IncrementalProcessor (tests the orchestrator)

6. Test each layer as you go:
   - Unit tests first (component-level)
   - Integration tests next (CLI integration)
   - Behavioral tests (correctness validation)
   - UAT tests (user workflows)
   - Performance tests (benchmark validation)

7. Final verification:
   pytest -m story_5_7 --cov=src/data_extract/cli/batch

================================================================================
                          FILES MANIFEST
================================================================================

Test Files (52 tests, 3012 total lines):
  ✓ tests/behavioral/epic_5/__init__.py
  ✓ tests/behavioral/epic_5/conftest.py
  ✓ tests/behavioral/epic_5/test_incremental_behavior.py
  ✓ tests/unit/test_cli/test_incremental_processor.py
  ✓ tests/integration/test_cli/test_batch_incremental.py
  ✓ tests/uat/journeys/test_journey_7_incremental_batch.py
  ✓ tests/performance/test_incremental_performance.py

Documentation:
  ✓ docs/artifacts/story_5_7_test_skeleton_summary.md
  ✓ docs/artifacts/story_5_7_test_file_structure.txt
  ✓ docs/artifacts/story_5_7_test_quick_reference.md
  ✓ docs/artifacts/STORY_5_7_COMPLETE.txt (this file)

================================================================================
                            NEXT STEPS
================================================================================

1. Implement components in src/data_extract/cli/batch.py
2. Run unit tests first (lowest-level validation)
3. Run integration tests (CLI integration)
4. Run behavioral tests (correctness validation)
5. Run UAT tests (user workflows)
6. Run performance tests (baseline validation)
7. Final full test suite: pytest -m story_5_7

Expected timeline: 4-6 hours for complete implementation + testing

================================================================================
                            CONTACT & NOTES
================================================================================

This is a comprehensive ATDD test skeleton designed to drive the implementation
of Story 5-7 (Batch Processing Optimization and Incremental Updates).

All tests follow Test-Driven Development (TDD) RED phase patterns:
- Tests are written BEFORE implementation
- Tests initially skip with "Implementation pending"
- Assertions are guarded by pytest.skip()
- Import errors are handled gracefully

The test suite validates:
- 52 test cases across 5 layers (unit, integration, behavioral, UAT, performance)
- All Story 5-7 acceptance criteria
- Performance baselines and requirements
- User workflows and journeys
- State management and persistence
- CLI integration points

Total effort invested: ~3,012 lines of test code ready for implementation.

================================================================================
