"""Shared DTOs for CLI, API, and UI integration."""

from __future__ import annotations

from datetime import datetime, timezone
from enum import Enum
from typing import Any, Dict, List, Optional

from pydantic import BaseModel, Field


class JobStatus(str, Enum):
    """Processing job lifecycle state."""

    QUEUED = "queued"
    RUNNING = "running"
    COMPLETED = "completed"
    PARTIAL = "partial"
    FAILED = "failed"


class EvaluationVerdict(str, Enum):
    """Governance evaluation verdict."""

    GOOD = "good"
    WATCH = "watch"
    BAD = "bad"


class FileFailure(BaseModel):
    """Failure details for a single source file."""

    path: str
    error_type: str
    error_message: str
    retry_count: int = 0
    source_key: Optional[str] = None


class ProcessedFileOutcome(BaseModel):
    """Success details for a single processed file."""

    path: str
    output_path: str
    chunk_count: int = 0
    stage_timings_ms: Dict[str, float] = Field(default_factory=dict)
    source_key: Optional[str] = None


class SemanticArtifact(BaseModel):
    """Artifact metadata generated by semantic processing."""

    name: str
    path: str
    artifact_type: str
    format: Optional[str] = None
    size_bytes: int = 0


class SemanticOutcome(BaseModel):
    """Semantic stage status and produced outputs."""

    status: str = "disabled"
    reason_code: Optional[str] = None
    message: Optional[str] = None
    summary: Dict[str, Any] = Field(default_factory=dict)
    artifacts: List[SemanticArtifact] = Field(default_factory=list)
    stage_timings_ms: Dict[str, float] = Field(default_factory=dict)


class GovernanceEvidenceRef(BaseModel):
    """Evidence pointer for a governance check result."""

    artifact_path: Optional[str] = None
    field_path: Optional[str] = None
    value_snapshot: Any = None


class GovernanceCheckResult(BaseModel):
    """Evaluation result for one governance check."""

    check_id: str
    metric: str
    critical: bool = False
    weight: float = 1.0
    operator: str = "gte"
    target: Optional[Any] = None
    observed: Any = None
    passed: bool = False
    score: float = Field(default=0.0, ge=0.0, le=100.0)
    reason_code: Optional[str] = None
    evidence: List[GovernanceEvidenceRef] = Field(default_factory=list)


class GovernanceMilestoneResult(BaseModel):
    """Evaluation rollup for one governance milestone."""

    milestone_id: str
    title: str
    weight: float = 1.0
    status: str = "passed"
    score: Optional[float] = Field(default=None, ge=0.0, le=100.0)
    skipped: bool = False
    critical_failed: bool = False
    checks: List[GovernanceCheckResult] = Field(default_factory=list)
    reason_codes: List[str] = Field(default_factory=list)


class GovernanceEvaluationOutcome(BaseModel):
    """Full governance evaluation payload for a process result."""

    policy_id: str
    policy_version: str
    overall_score: float = Field(ge=0.0, le=100.0)
    verdict: EvaluationVerdict
    milestones: List[GovernanceMilestoneResult] = Field(default_factory=list)
    failed_critical_checks: List[str] = Field(default_factory=list)
    reason_codes: List[str] = Field(default_factory=list)
    metadata: Dict[str, Any] = Field(default_factory=dict)


class ProcessJobRequest(BaseModel):
    """Request contract for processing files through the pipeline."""

    input_path: str
    output_path: Optional[str] = None
    output_format: str = "json"
    chunk_size: int = 512
    include_metadata: bool = False
    per_chunk: bool = False
    organize: bool = False
    strategy: Optional[str] = None
    delimiter: str = "━━━ CHUNK {{n}} ━━━"
    recursive: bool = False
    incremental: bool = False
    force: bool = False
    resume: bool = False
    resume_session: Optional[str] = None
    preset: Optional[str] = None
    non_interactive: bool = False
    include_semantic: bool = False
    include_evaluation: bool = True
    evaluation_policy: str = "baseline_v1"
    evaluation_fail_on_bad: bool = False
    semantic_report: Optional[bool] = None
    semantic_report_format: Optional[str] = None
    semantic_export_graph: Optional[bool] = None
    semantic_graph_format: Optional[str] = None
    semantic_duplicate_threshold: Optional[float] = None
    semantic_related_threshold: Optional[float] = None
    semantic_max_features: Optional[int] = None
    semantic_n_components: Optional[int] = None
    semantic_min_quality: Optional[float] = None
    pipeline_profile: Optional[str] = None
    continue_on_error: bool = True
    source_files: List[str] = Field(default_factory=list)
    idempotency_key: Optional[str] = None


class ProcessJobResult(BaseModel):
    """Result contract for process/retry operations."""

    job_id: str
    status: JobStatus
    total_files: int
    processed_count: int
    failed_count: int
    skipped_count: int = 0
    output_dir: str
    session_id: Optional[str] = None
    processed_files: List[ProcessedFileOutcome] = Field(default_factory=list)
    failed_files: List[FileFailure] = Field(default_factory=list)
    stage_totals_ms: Dict[str, float] = Field(default_factory=dict)
    started_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    finished_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    artifact_dir: Optional[str] = None
    request_hash: Optional[str] = None
    exit_code: int = 0
    semantic: Optional[SemanticOutcome] = None
    evaluation: Optional[GovernanceEvaluationOutcome] = None


class RetryRequest(BaseModel):
    """Request contract for retry operations."""

    last: bool = False
    session: Optional[str] = None
    file: Optional[str] = None
    backoff: bool = False
    non_interactive: bool = False
    output_format: str = "json"
    chunk_size: int = 512


class SessionSummary(BaseModel):
    """Session summary for listing and API responses."""

    session_id: str
    status: str
    source_directory: str
    total_files: int
    processed_count: int
    failed_count: int
    updated_at: datetime
